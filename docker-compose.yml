# Standard Docker Compose configuration
# Works on x86/AMD64 systems (Linux, Windows, Intel Mac)
# For Raspberry Pi, use: docker-compose.raspberry-pi.yml

version: '3.8'

services:
  gpt-researcher:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: gpt-researcher
    ports:
      - "8000:8000"
    environment:
      # Required API Keys - set these in .env file
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - TAVILY_API_KEY=${TAVILY_API_KEY:-}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      
      # Optional: Local LLM support
      - LLM_PROVIDER=${LLM_PROVIDER:-openai}
      - FAST_LLM_MODEL=${FAST_LLM_MODEL:-gpt-4o-mini}
      - SMART_LLM_MODEL=${SMART_LLM_MODEL:-gpt-4o}
      
      # Research configuration
      - MAX_SEARCH_RESULTS_PER_QUERY=${MAX_SEARCH_RESULTS_PER_QUERY:-5}
      - MAX_ITERATIONS=${MAX_ITERATIONS:-4}
      - RETRIEVER=${RETRIEVER:-tavily}
      
      # Server configuration
      - WORKERS=2
      - HOST=0.0.0.0
      - PORT=8000
    
    volumes:
      # Persist research outputs
      - ./outputs:/usr/src/app/outputs
      # Persist logs
      - ./logs:/usr/src/app/logs
      # Mount .env file
      - ./.env:/usr/src/app/.env:ro
    
    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    
    # Restart policy
    restart: unless-stopped
    
    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

# To use this file:
# 1. Copy .env.example to .env and add your API keys
# 2. Build and run:
#    docker-compose up -d
